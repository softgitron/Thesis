\chapter{PLANNING OF THE TEST AUTOMATION SYSTEMS}\label{chapter:planning_of_the_test_automation_systems}
This chapter will explain the forming of the requirements and the creation of different design documents. The first section will concentrate on the identified requirements and tell how they were formed. The second section describes how the management planning was done. Finally, the technical planning process will be walked through in the third section.

\section{Requirements}
The final requirements list can be found in the \autoref{appendix:projects_requirements}. Requirements in the \autoref{appendix:projects_requirements} are divided into four distinctive categories. Categories are general project, management, technical and other requirements. This section's latter subsections are also divided using the same logic as the appendix. The next \autoref{subsection:requirements_gathering} is still different and considers requirement gathering and management processes instead of requirements.

\subsection{Requirements gathering}\label{subsection:requirements_gathering}
At the beginning of the project, the main focus was purely on general information gathering and during that period, requirements were not explicitly gathered. However, the requirements were still often encountered during general information gathering and were implicitly collected. Unfortunately, no explicit recordings of the requirements were done at this point, but all the essential data was still logged for later analysis and use.

Requirements gathering and information gathering was a highly iterative process during the project. Initially, requirements were extensive because the Hubshare team's knowledge about the test automation was not especially high, and the team could not directly state what they wanted from the test automation. To overcome the gaps in knowledge, multiple methods to collect the information, like interviews and surveys, were used to reach the actual requirements of the test automation system.

In addition to a lack of test automation knowledge, certain aspects existed of which precise requirements could not be constructed. For example, it was known that the old code base's coverage must be improved, but it needed to be discovered precisely how. Lack of knowledge made it impossible to define more exact requirements without significant additional research.

Because of the mentioned problems, most of the requirements ended up being vague, which is not an optimal state. According to literature, satisfactory software requirements should be, among other things, unambiguous and testable to ensure that requirement produces value \cite{firesmith2003specifying}. However, during this project, less clear requirements were a necessity because better information was not available. Vagueness reduced the usability of the requirements, but they were still valuable for the project. Requirements guided the research and general directions of the project.

\subsection{Requirements management}
Even though requirements appear cleanly in the appendix, this was not always the case during the project. Before the construction of the list found in the \autoref{appendix:projects_requirements}, requirements were not centrally collected anywhere. Instead, they were kept in an unstructured form in the project's documentation. Generally, an unclear requirement management process is not recommended because it exposes the requirements for oblivion and reduces the clarity of the project. However, at least requirements were somehow managed as seen necessary by the literature \cite{hood2007requirements}.

Most of the requirements in the \autoref{appendix:projects_requirements} contain four columns. The first column has a unique ID of the requirement that can be used to identify the requirement uniquely. The second column has a source, which is used to keep track of the information source, where the requirement has initially been found based on the first occurrence of the requirement. Keeping track of the source is helpful if the original context for the requirement must be found. In the third column, the most important stakeholder is recorded. Finally, in the fourth column, the requirement itself is specified.

\subsection{General project requirements}
General requirements available in the \autoref{appendix:projects_requirements} worked as a guiding principle for the whole test automation project. Because of the considerable impact, these requirements were quite vague. These requirements defined even the subject of this thesis. There is an almost direct mapping between these requirements and the three research questions. General requirements were identified already during the first meeting described in the \autoref{subsection:beginning_of_the_project}.

\subsection{Management requirements}
Management requirements are requirements that are related to the management of the test automation system. Compared to general project requirements, management requirements contain more granular requirements related to management. For example, requirement related to daily test automation processes considers only \gls{dod} for the test automation instead of requiring, for example, extensive management documents.

Most of the requirements were collected during the interviews. Interestingly no new management requirements could be found using the survey even though \autoref{survey_question:works_well_in_processes} was directly about the management. There were likely fewer responses to the management questions because most respondents had a technical background.

\subsection{Technical requirements}
During the information gathering, quite a few technical requirements were collected. As seen from the \autoref{appendix:projects_requirements}, there are two types of technical requirements, functional and non-functional. Functional requirements define what software will do, while non-functional requirements will define how it will do it \cite{ieee1990glossary}. Some of the functional requirements are pretty specific, like, for example, the requirement about the automatic running of the \glsfirst{ci} pipeline. On the other hand, non-functional requirements, like requirements about test automation speed, are pretty vague. For example, regarding test automation speed, in the future, it could be defined more precisely, what is the acceptable execution speed for test automation cases, so that the development of the test automation framework could be guided more precisely.

While most functional requirements were common to all test automation levels, some requirements are specific to certain types of test automation. For example, there is a requirement stating that there must be a way to set the database state easily. This requirement does not affect unit testing because unit tests do not have access to the database.

\subsection{Other requirements}
Other requirements contain some requirements that are too small to be general project requirements but do not fit either management or technical requirements. As seen from the \autoref{appendix:projects_requirements}, these requirements are mainly related to education, documentation and motivation.

\section{Management planning}
Management planning was done based on the gathered information in conjunction with Hubshare and M-Files \gls{qa} management. Proposals of the management plans were written by the engineer that advanced the Hubshare test automation project. Based on the comments to the plans, proposals were improved until they were seen as good enough for use. Subjects for different documents were organically decided based on the collected information. The following subsections have reasoning for different documents' existence.

\subsection{Thesis}
This thesis aims to explain why different things went the way they happened and the root reasons behind the different decisions. While other documents produced during the project only provide outcomes, this thesis also concentrates on the journey towards the final solution(s). The thesis is the most comprehensive documentation of the processes behind the project.

\subsection{Introduction plan}
An introduction plan is a plan that defines the introduction order of different testing system aspects. The plan presents how the test automation system will be programmed and how the system will be introduced to the team. The plan was constructed based on the Hubshare team's wishes and approximations of the education need. An important factor during the creation of the introduction plan was the estimation of the time it would take to create the different levels of the system.

\subsection{Project management plan}
A project management plan was done based on the requirements. The idea during the creation of the document was to include everything in the document that would be needed in the daily operation of the test automation system. The document was crafted based on the information gathered earlier during the project.

\subsection{Other documents}
In addition to the thesis, introduction plan and project management plan, no other official documents were created. However, multiple unofficial documents were still crafted during the project. The most notable additional document was the technical manual, created to guide the usage of the test automation framework. Another notable collection of documents created during the project is a collection of custom education materials. The materials were used to increase Hubshare team members' knowledge of the new test automation system. In addition, documents related to the survey and interviews were crafted as additional documents.

\section{Technical planning}
Technical planning was done based on the identified technical requirements and the restrictions set by the technologies like programming languages used in the software. Initially, the planning was mainly done by sketching higher levels of the architecture using \gls{c4} architecture model. \gls{c4} is easy to learn "abstraction-first" visual design language used for presenting software architectures \cite{brown2022c4}. \gls{c4} architecture was used for creating the architecture because it was known beforehand by the architect.

After the initial sketching of the higher levels, the architecture was turned into the test automation framework code. Coding was started before finalising \gls{c4} model's lower levels because, during the creation of the initial architecture, there were too many technical open questions that had to be resolved before the final architecture could be defined. Open technical questions required practical experimentation with the code in order to be resolved, so the early beginning of the programming was a necessity. For example, it was known that it would be good to be able to roll back the database to its initial state quickly in the integration and system-level tests. However, it was not known if this would ever be feasible or if it would be required, for example, to manually remove all new entries to the database after executions of each test case. Further explanation for the selected working mode can be found in the \autoref{subsection:ways_of_working}.

\subsection{Unit testing architecture}
Initially, it was believed that creating the unit testing frameworks would be easy. As mentioned in the \autoref{subsection:unit_testing}, unit tests are supposed to be simple. However, because test automation was not considered during the creation of the original software architecture as stated in the \autoref{section:case_new_test_automation_system_for_hubshare}, creating the unit test cases for the code was more challenging than initially anticipated. During planning, two technical problems were discovered that hindered the introduction of the unit tests. The first technical problem was caused by the dependency handling of the backend and frontend programs. Dependency handling is very convenient during the development but complicates the unit testing framework's development. The second issue was higher than the anticipated coupling of the components on the code level, which made mocking more complex.

Hubshare's backend is written in C\#, and backend unit testing tools had to be selected based on the language. Main test automation tools for the primary framework, mocking and assertions were mainly selected based on the tool's popularity. Additionally, specific extra tools for more complex cases were developed in-house. Interestingly, no open-source tools were available for the C\# language that would be powerful enough to stub or mock any built-in methods. New tools for such purposes were built in-house to simplify the mocking of complex cases and to avoid additional costs. Similarly, C\# testing tools did not have excellent support for handling private fields and methods, so new custom tools were also built for that purpose.

Hubshare's frontend is programmed using TypeScript and Angular. There are only two JavaScript test frameworks that have clear official support for the Angular test automation, Angular's default framework Jasmine \cite{angular2022testing}, and Jest \cite{jest2022testing}. Initially, Jest was selected due to its unmatched popularity \cite{stateofjs2021}. However, in the end, Jest could not be selected as a framework for Hubshare's frontend application. Because of the dependency handling, Jest was extremely slow for this particular application due to TypeScript on-demand compilation latency. In the end, Angular's default Karma + Jasmine stack was selected as the main framework instead due to the much faster running time.

\subsection{Integration testing architecture}\label{subsection:integration_testing_architecture}
As mentioned in the \autoref{subsection:integration_testing}, integration testing can be divided into component and system-level integration testing. During the planning, it was identified that separate automation testing systems for both integration testing types were needed. Component-level integration testing focus was set to more complex unit testing-like scenarios, where also database access would be needed. Database testing was crucial because the functionality of the backend leaned heavily on database access. On the more system level integration testing, \gls{api} testing was selected as the approach to \glsfirst{e2e} verify the backend functionality.

Because the requirements for the integration testing frameworks were higher than for the unit testing frameworks, the architecture was, from the start, designed to be significantly more complex. While sketching the initial integration testing framework's architectural pictures, it was noticed that both integration testing, API testing and even system testing had similar requirements for the testing framework. All the different automation systems required the preparation of the database and some installation of the application. Due to the standard requirements of different automation testing systems, the architecture was designed to share large parts of the environment code among different test automation systems. Sharing code lowered the amount of code required for the overall test automation system and decreased the development time.

The greatest challenge with the integration testing architecture was database access. Access to an actual database was always necessary in this test automation case because the application required advanced database functionalities. In the ideal world, the test framework should always be able to reset the database to its initial state before the next test case so that there would not be a possibility that the test cases would accidentally interfere with each other. However, technically, the ideal situation is hard to achieve because resetting the database state is generally slow. Nevertheless, during the integration tests, it should be fast so that the running of the integration tests would be manageable. Alternatively, database modifications can be rolled back manually, but this strategy increases the risk of errors and the time required to write new cases. So the alternative approach is not perfect either.

\subsection{System testing architecture}
As said in the \autoref{subsection:integration_testing_architecture} also system automation testing framework was already considered during the creation of the integration testing framework. Early planning made designing the system testing automation easier because there was no need to design application and database preparation from the ground up. Instead, the planning of the system testing architecture concentrated on the upper layer of the system testing. The only extra step that the system testing test automation required was support for preparing frontend applications automatically.

Cypress was selected as a primary framework for the system testing. The selection was made based on its popularity \cite{stateofjs2021}. Additionally, the framework's unique features contributed to its selection. Unlike most of the frontend \gls{e2e} testing frameworks, Cypress does not use Selenium as a backend technology, which removes all the Selenium-based drawbacks, like the manual waiting of the component loading and overall slowness of the framework. Cypress is also easier to introduce into production because it is a complete package, and there is no need to select multiple test automation framework components manually. \cite{cypress2022features, cypress2022how}

\section{Other planning aspects}\label{section:other_planning_aspects}
Under this section, some other planning aspects usually taken into account during the project are explained. These aspects were not considered during this project due to various reasons.

As stated in the \autoref{subsection:prioritization_of_the_test_automation} \glsfirst{roi} should be considered during the creation of the test automation. During this project, the \gls{roi} was not considered because, based on the M-Files' prior experiences with the test automation, automation overall has positive \gls{roi}, and due to that, \gls{roi} calculations for this project were not demanded by the management. However, as mentioned in the \autoref{subsection:software_testing}, exhaustive testing is impossible due to infeasible resource requirements. Due to that, in the future, some \gls{roi} calculations must be made so that the test automation efforts will be correctly focused.

Another common planning aspect that was not entirely planned was the project's schedule. During the planning, the Gantt chart for the project was outlined. However, the Gantt chart's time estimations were never fully completed. Time estimates were not completed because any of the persons involved in the time estimation were not confident enough to estimate the time that different project parts would take. The difficulty of coming up with exact requirements mentioned in the \autoref{subsection:requirements_gathering} can also be seen as one significant factor in why the clear schedule could not be formed.